# best_classification_models
Esse cÃ³digo implementa um pipeline completo de Machine Learning em R para prever churn de clientes e comparar vÃ¡rios modelos, usando o ecossistema tidymodels.

Em termos simples:

ğŸ‘‰ Ele testa vÃ¡rios algoritmos de classificaÃ§Ã£o para descobrir qual prevÃª melhor quais clientes vÃ£o cancelar (churn).

Vou explicar por partes.

ğŸ”¹ 1. Objetivo geral

O script responde Ã  pergunta:

â€œQual modelo classifica melhor clientes que vÃ£o dar churn?â€

Para isso, ele:

Usa uma base do Kaggle

Treina vÃ¡rios modelos

Compara desempenho

Ajusta o melhor (XGBoost Tuned)

Avalia no conjunto de teste

ğŸ”¹ 2. Carregamento de dados
customer_churn_dataset <- read_excel(...)


LÃª uma planilha Excel com dados de clientes.

Depois:

mutate(churn = factor(...))
select(-customer_id)


Transforma churn em variÃ¡vel categÃ³rica (Yes/No)

Remove o ID (nÃ£o ajuda na previsÃ£o)

ğŸ”¹ 3. DivisÃ£o treino / teste
split <- initial_split(df, prop = 0.80, strata = churn)


Divide:

80% â†’ treino

20% â†’ teste

MantÃ©m proporÃ§Ã£o das classes (strata)

Depois:

vfold_cv(train, v = 5)


Cria validaÃ§Ã£o cruzada com 5 folds.

ğŸ‘‰ Serve para evitar overfitting.

ğŸ”¹ 4. PrÃ©-processamento (Recipe)

Essa Ã© uma das partes mais importantes:

churn_recipe <- recipe(...) |>


Define um pipeline automÃ¡tico:

O que ele faz:
âœ… 1. Dummies
step_dummy(all_nominal_predictors())


Transforma variÃ¡veis categÃ³ricas em nÃºmeros.

Ex:
gender = Male/Female â†’ colunas binÃ¡rias.

âœ… 2. Balanceamento (SMOTE)
step_smote(churn)


Cria exemplos artificiais da classe minoritÃ¡ria.

ğŸ‘‰ Corrige desbalanceamento.

âœ… 3. Remove colunas inÃºteis
step_zv()


Remove colunas sem variaÃ§Ã£o.

âœ… 4. NormalizaÃ§Ã£o
step_normalize()


Coloca tudo na mesma escala.

Importante para:

RegressÃ£o

Boosting

Redes

ğŸ”¹ 5. MÃ©tricas de avaliaÃ§Ã£o
metrics <- metric_set(roc_auc, accuracy, sens, spec)


Ele avalia usando:

MÃ©trica	Significado
AUC	Capacidade de separar classes
Accuracy	% de acertos
Sens	Recall da classe positiva
Spec	Recall da negativa

ğŸ‘‰ Em churn, sensibilidade Ã© crucial.

ğŸ”¹ 6. Modelos testados

O cÃ³digo cria 5 modelos:

ğŸ“Œ 1. RegressÃ£o LogÃ­stica
logistic_reg()


Baseline linear.

ğŸ“Œ 2. Ãrvore
decision_tree()


Modelo simples, interpretÃ¡vel.

ğŸ“Œ 3. Random Forest
rand_forest()


Muitas Ã¡rvores â†’ robusto.

ğŸ“Œ 4. AdaBoost
C5.0


Boosting clÃ¡ssico.

ğŸ“Œ 5. XGBoost
boost_tree(engine="xgboost")


Modelo principal (mais forte).

ğŸ”¹ 7. Workflows
make_wf <- function(model)


Cria uma funÃ§Ã£o para juntar:

PrÃ©-processamento

Modelo

Em um sÃ³ objeto.

ğŸ‘‰ Evita erro e repetiÃ§Ã£o.

ğŸ”¹ 8. Treinamento com Cross-validation
fit_resamples()


Treina cada modelo em 5 folds.

Isso gera:

MÃ©tricas mÃ©dias

Erros padrÃ£o

PrevisÃµes

ğŸ‘‰ AvaliaÃ§Ã£o estatisticamente mais confiÃ¡vel.

ğŸ”¹ 9. ComparaÃ§Ã£o dos modelos
results <- bind_rows(...)


Junta tudo numa tabela:

Modelo	MÃ©trica	MÃ©dia

E ordena pelo AUC.

Resultado interpretado:

Boosting foi melhor
Random Forest conservador
LogÃ­stica mais sensÃ­vel

ğŸ”¹ 10. VisualizaÃ§Ãµes

Ele cria vÃ¡rios grÃ¡ficos:

ğŸ“ˆ ROC
roc_curve()

ğŸ“‰ Precision-Recall
pr_curve()

ğŸ“Š Densidade
geom_density()

ğŸ“ˆ Gain / Lift
gain_curve()


Esses grÃ¡ficos mostram:

SeparaÃ§Ã£o das classes

Qualidade da probabilidade

Ganho de negÃ³cio

ğŸ”¹ 11. Treinamento final

Depois de escolher XGBoost:

final_fit <- fit(wf_xgb, data = train)


Treina com 100% do treino.

E testa:

predict(... test ...)


Avalia no conjunto nunca visto.

ğŸ”¹ 12. Hyperparameter Tuning

Aqui ele entra em nÃ­vel avanÃ§ado.

tune_grid()


O cÃ³digo:

1ï¸âƒ£ Cria modelo com parÃ¢metros livres
2ï¸âƒ£ Gera combinaÃ§Ãµes
3ï¸âƒ£ Testa em CV
4ï¸âƒ£ Escolhe o melhor

ParÃ¢metros ajustados:

trees

depth

learning rate

mtry

gamma

ğŸ”¹ 13. DetecÃ§Ã£o de Overfitting

VocÃª faz algo muito bom aqui:

Percebe que:

sens = 1.00


Ã‰ suspeito.

E conclui:

ğŸ‘‰ Overfitting.

Depois:

Reduz intervalo

Reexecuta tuning

Corrige

Isso Ã© prÃ¡tica profissional.

ğŸ”¹ 14. Modelo final otimizado

ApÃ³s o tuning:

final_fit2


VocÃª obtÃ©m:

MÃ©trica	Valor
Sens	0.67
Spec	0.93
AUC	0.80

ğŸ‘‰ Excelente equilÃ­brio.

ğŸ”¹ 15. Resultado prÃ¡tico

No fim, o cÃ³digo constrÃ³i:

âœ… Um modelo produtivo
âœ… Bem validado
âœ… Sem overfitting
âœ… Otimizado para churn

E conclui:

Captura ~2/3 dos churns reais
MantÃ©m poucos falsos alarmes

ğŸ“Œ Em resumo (bem direto)

Esse cÃ³digo:

âœ”ï¸ Importa dados
âœ”ï¸ Limpa
âœ”ï¸ Balanceia
âœ”ï¸ PrÃ©-processa
âœ”ï¸ Treina 5 modelos
âœ”ï¸ Compara
âœ”ï¸ Escolhe XGBoost
âœ”ï¸ Ajusta hiperparÃ¢metros
âœ”ï¸ Valida corretamente
âœ”ï¸ Gera grÃ¡ficos
âœ”ï¸ Produz modelo final

Ou seja:

ğŸ‘‰ Ã‰ um pipeline completo de Data Science para churn.

NÃ­vel: Pleno / SÃªnior em ML aplicado.
